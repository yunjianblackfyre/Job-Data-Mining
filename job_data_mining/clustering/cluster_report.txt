聚类报告：

一.参数明细
    word2vector:
        文档数:20W
        文档平均长度:200词
        词向量维度:10
        词上下文长度:6词
    kmeans:
        聚类数量:100（聚类数作为X轴，误差值为y轴，y=f(x)函数大约在x=100处收敛）
    
二.聚类结果
    1.人工过滤:废弃聚类64个，保留36个
    2.对于每一个聚类，平均有30%左右的词被去除
    
三.典例展示
    1.优质聚类
        搜索/推荐类职位关键词:
            '排名', '排序', '分析模型', '文本挖掘', 'OLAP', '数据集市', '推荐算法', '数据抽取', '信息抽取', '分词', '数学模型', '知识图谱', '网络爬虫', '检索', '风控', '抽取', '数据清洗', '分析方法', '关键词', '抓取', '文本', '核心算法', '推荐系统', '业务模型', '结构化', '性格化', '爬虫', '报表需求', '参数', '数据统计', '模型设计', '预测', '应用场景', '特征', '分析挖掘', '优化方案', '采集', '调度', '转换', '海量', '统计分析', '用户画像', '搜索引擎', '数据采集', '数据模型', '提取', '数据建模', '分类', '实时', '深度', '搜索', '可视化', '海量数据', '数据仓库', '数据处理', '挖掘', '数据挖掘', '模型', '数据分析', '数据'
        
        机器人/人工智能类职位关键词：
            '激光雷达', '人脸', '分割', 'SLAM', '处理算法', 'RNN', '逆向', '目标检测', '特征提取', 'HALCON', 'CUDA', '语音识别', 'CNN', '数学功底', '人脸识别', '决策树', 'SVM', '论文', 'NLP', 'GPU', '神经网络', '图像识别', '回归', '语音', '传感器', 'CAFFE', '数学基础', '聚类', '算法研究', '模拟', '机器视觉', '信号处理', '图形学', '检测', '机器人', '模式识别', 'OPENCV', '图像', '人工智慧', '识别', '深度学习', '图像处理', '机器学习', '视觉'
        
        机电/自动化类职位关键词:
            '分析仪', 'VHDL', '电机控制', 'EDA', 'SIMULINK', 'PROTEL', '电机', 'IAR', 'VERILOG', 'DESIGNER', '器件', '控制算法', '电路设计', '硬件电路', 'LABVIEW', 'KEIL', '示波器', 'GDB', '汇编', '运动控制', '模拟电路', '信号', '汇编语言', '总线', '数字电路', 'PCB', '串口', 'PLC', 'MCU', 'FPGA', '上位机', 'UART', '电路', 'CAN', '原理图', '仿真', 'USB', 'DSP', 'SPI', 'MATLAB', '单片机', 'ARM', '软件测试', '硬件', '嵌入式'
        
        视觉设计类职位关键词:
            '美学', '色彩感觉', '审美意识', '用户群', '版式', '视觉表现', '触觉', '网页布局', '设计创意', '构思新颖', '美感', '表现力', '整体布局', '文字功底', '设计趋势', '色彩感', '观察力', '设计风格', '吸引力', '美术基础', '传达', '洞察力', '艺术',  '审美观', '创作', '色彩搭配', '独特', '独到', '想象力', '设计理念', '手绘', '视觉效果',  '文字', '擅长', '敏锐', '见解', '细节', '活跃', '色彩', '美术功底', '审美', '网页设计'
            
    2.劣质聚类
            'PROFACE', 'UTM', 'RGF', '京都', 'MAIL', 'CO', 'COLTD', 'BEIJING', 'JP', 'INTOUCH', 'SOFTWARE', 'JOB', '西城', '登录', '支付宝', '小姐', '信', '智联', '公司官网', '波特', '营', '十万', '主页', '官网', '月收入', '网址', 'CN', '商城', '公众', 'WWW', 'COM', '微信'
            
            '英语口语', '中英文', '英文文献', '文献', '日文', '英语水平', '普通话', '外语', '读懂', 'CET', '口语', '英文文档', '英文资料', '流利', '技术资料', '读写', '写作能力', '英语四级', '读写能力', '口头', '书面', '阅读英文', '日语', '英文', '英语', '阅读'
            
    3.摇摆聚类
        产品|运营类职位关键词:
            '平衡性', '运营数据', '提出产品', '用性测试', '优化建议', '分析结果', '竞争对手', '跟踪产品', '细化', '分析用户', '合理性', '搜集', '不断完善', '针对性', '潜在', '提炼', '改进方案', '数值', '最优', '平衡', '用户操作', '判断', '用户研究', '提出合理', '影响', '正确', '变化', '落实', '角度', '可行性', '产品规划', '做出', '最终', '引导', '决策', '进行分析', '落地', '给出', '梳理', '结果', '意见', '项目需求', '准确', '产品进行', '输出', '推进', '把控', '设计方案', '产品需求', '讨论', '用户需求', '收集', '资源', '合理', '公司产品', '调整', '评估', '建立', '建议', '业务需求', '跟进', '客户需求', '根据公司', '整体', '提出', '高效', '用户', '方案', '解决方案', '规划', '制定', '需求'
            
四.优化分析
    1.人工过滤
        机器直接产生的聚类结果是不能直接用于推荐的。
        一是因为关键词常常与一些非关键词混在一起，比如劣质聚类中的“登陆”与“波特”。
        二是因为有一些聚类基本都是一些非关键词（噪音），这种类需要直接剔除。
        如何提高人工过滤的质量和效率呢？
        (1).进行过滤的最好是这方面的专业人士，比如后台类型的聚类过滤交给后台工程师，产品聚类过滤交给产品经理等等。
            （在此，我们可以推测拉勾的推荐和搜索体验优于51JOB，其中原因可能就是因为拉勾主修互联网职位，而51JOB则包含几乎所有领域职位，人工过滤关键词的难度系数可想而知。）
        (2).第一次过滤后，我们可以将留下来的关键词保存在一个词库中，并定期对其进行更新，更新周期视行情而定。这样下次过滤时，可以自动去掉一些没用的关键词。
        (3).通过计算idf值，对聚类中的关键词进行排序，将那些过于冷门的词（idf值过高）和那些过于普遍的词（idf值过低）往后面排，增加人工过滤时的批量删除操作。
        
    2.机器训练
        (1).优化
            在总结优化这块内容之前，我做了一个实验，将原始的文档分词后形成的词序列作为样本，计算各个词语的上下文相似度（在计算词向量之前，思想与词向量算法一致）。
            python3 sim_test.py 机器学习 数据挖掘 相似度:0.94
            如此高的相似度得益于他们的上下文有这些词重合，而且这些词出现的频率很高，示例如下（格式：词,词频）：
            ('HADOOP', 346)，('海量数据', 368)('模式识别', 381)('图像处理', 389)('人工智慧', 392)('平台', 397)('具备', 431)('产品', 431)('系统', 452)
            ('工作地址', 459)('PYTHON', 462)('模型', 584)('相关专业', 710)('能力', 741)('大数据', 856)('深度学习', 879)('数据分析', 925)
            ('负责', 1017)('数据', 1085)('分析', 1120)('经验', 2118)('算法', 2542)
            
            真实场景下，机器学习和数据挖掘确实是一对关联度极高的关键词，相似度计算结果是合理的。但是上述的上下文中，有那么一些词会混淆视听！
            工作地址：几乎所有职位都有这个词
            产品：互联网相关的职位几乎都有这个词
            系统：工程类相关职位几乎都有这个词
            那么这种词如果太多，那么是否会将那些没多大关联的词都算出极高的相似度呢？
            答案是肯定的：神经网络 英文水平 有0.5的相似度，上下文重合的词语中高频词有
            ('优先', 211)('能力', 214)('经验', 230)('熟悉', 320)('算法', 338)
            
            这样看来，那些覆盖面太广的词语可以用其IDF值消去。IDF低于某个阈值的就不让其参与word2vect训练。
            阈值取一个合适的值很重要，因为阈值太高，则训练数据过少，阈值太低，又会发生上述问题。此阈值只有经过反复测试才能得出
        (2).缺点
            python3 sim_test.py 英语 日语 相似度:0.87
            根据数据库元数据，我们得知，都带有英语、日语的招聘信息只占总信息的0.04左右，也就是说对英语有要求的职位，和对日语有要求的职位彼此独立
            那么这俩字的关联度那么高呢？
            根据一些抽样调查，对这两种语言有要求的公司基本都外包日本和英美的业务，而且多数职位为软件工程师
            日语和英语的上下文语言环境基本类似，所以它们才有如此高的相似度。不过这样的结果，是推荐/搜索所不能接受的，
            不能因为某用户选择了英语类的外包软件工作，就给他推荐日语类的工作，这样很尴尬
    总结：
        算法方面我们可以尝试用其他聚类器，比如LDA，LDA通过计算多个序列的最大概率，可以避免(2)。
        人工过滤方面，对某个行业有一定专业知识的人对某个特定聚类的过滤整理将会非常有效。
